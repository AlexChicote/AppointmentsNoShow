{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code:  200\n",
      "45\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "##Getting weather data\n",
    "url88 = 'https://www.wunderground.com/history/airport/SBVT/2016/4/29/\\\n",
    "CustomHistory.html?dayend=10&monthend=6&yearend=2016&req_city=&req_state\\\n",
    "=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo='\n",
    "\n",
    "respo = requests.get(url88)\n",
    "print('Status Code: ', respo.status_code)\n",
    "soup = BeautifulSoup(respo.content, 'lxml')\n",
    "soup\n",
    "\n",
    "###Obtaining the information for the days requested\n",
    "\n",
    "first_day = datetime.date(2016, 4, 29)\n",
    "final_day = datetime.date(2016, 6, 10)\n",
    "diff = final_day - first_day\n",
    "diff.days\n",
    "dies = []\n",
    "for item in range(1, diff.days+4):\n",
    "    link = soup.find_all('table')[1].find_all('tbody')[item].text\n",
    "    merda = link.replace('\\n', ' ').split()\n",
    "    dies.append(merda)\n",
    "len(dies[0])\n",
    "print(len(dies))\n",
    "\n",
    "##Creating dataframe and saving it for future cleaning\n",
    "\n",
    "column_names = ['dia','temp_high_f','temp_avg_f', 'Temp low F','Dew Point high F','Dew_Point_avg_F',\\\n",
    "                'Dew Point low F','humidity high %','humidity avg %','humidity low %',\\\n",
    "                'Sea Level Pressure high in', 'Sea Level Pressure avg (in)', 'Sea Level Pressure low in',\\\n",
    "                'Visibility high ml', 'Visibility avg ml','Visibility low ml', 'Wind high mph',\\\n",
    "                'Wind avg mph', 'Wind low mph',\\\n",
    "                'Precip sum', 'event', 'wtf', 'ves_a_cagar']\n",
    "print(len(column_names))\n",
    "\n",
    "final = pd.DataFrame(dies, columns=column_names)\n",
    "final.shape\n",
    "\n",
    "final.to_csv('weather2016.csv',index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code:  200\n",
      "376\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "url99 = 'https://www.wunderground.com/history/airport/SBVT/2014/1/1/\\\n",
    "CustomHistory.html?dayend=31&monthend=12&yearend=2014&req_city=&req_state\\\n",
    "=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo='\n",
    "\n",
    "respo = requests.get(url99)\n",
    "print('Status Code: ', respo.status_code)\n",
    "soupo = BeautifulSoup(respo.content, 'lxml')\n",
    "\n",
    "\n",
    "###Obtaining the information for the days requested\n",
    "import datetime\n",
    "first_day = datetime.date(2014, 1, 2)\n",
    "final_day = datetime.date(2014, 12, 31)\n",
    "diff = final_day - first_day\n",
    "diff.days\n",
    "diesa = []\n",
    "for item in range(1, diff.days+round(14)):\n",
    "    link = soupo.find_all('table')[1].find_all('tbody')[item].text\n",
    "    merda = link.replace('\\n', ' ').split()\n",
    "    diesa.append(merda)\n",
    "len(diesa[0])\n",
    "print(len(diesa))\n",
    "\n",
    "column_names = ['dia','temp_high_f','temp_avg_f', 'Temp low F','Dew Point high F','Dew_Point_avg_F',\\\n",
    "                'Dew Point low F','humidity high %','humidity avg %','humidity low %',\\\n",
    "                'Sea Level Pressure high in', 'Sea Level Pressure avg (in)', 'Sea Level Pressure low in',\\\n",
    "                'Visibility high ml', 'Visibility avg ml','Visibility low ml', 'Wind high mph',\\\n",
    "                'Wind avg mph', 'Wind low mph',\\\n",
    "                'Precip sum', 'event', 'wtf', 'ves_a_cagar']\n",
    "print(len(column_names))\n",
    "\n",
    "finala = pd.DataFrame(diesa, columns=column_names)\n",
    "finala.shape\n",
    "\n",
    "finala.to_csv('weather2014.csv',index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code:  200\n",
      "376\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "url100 = 'https://www.wunderground.com/history/airport/SBVT/2015/1/1/\\\n",
    "CustomHistory.html?dayend=31&monthend=12&yearend=2015&req_city=&req_state\\\n",
    "=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo='\n",
    "\n",
    "respons = requests.get(url100)\n",
    "print('Status Code: ', respons.status_code)\n",
    "soupaa = BeautifulSoup(respons.content, 'lxml')\n",
    "\n",
    "\n",
    "###Obtaining the information for the days requested\n",
    "import datetime\n",
    "first_day = datetime.date(2015, 1, 1)\n",
    "final_day = datetime.date(2015, 12, 31)\n",
    "diff = final_day - first_day\n",
    "diff.days\n",
    "diesaa = []\n",
    "for item in range(1, diff.days+round(13)):\n",
    "    link = soupaa.find_all('table')[1].find_all('tbody')[item].text\n",
    "    merda = link.replace('\\n', ' ').split()\n",
    "    diesaa.append(merda)\n",
    "len(diesaa[0])\n",
    "print(len(diesaa))\n",
    "\n",
    "column_names = ['dia','temp_high_f','temp_avg_f', 'Temp low F','Dew Point high F','Dew_Point_avg_F',\\\n",
    "                'Dew Point low F','humidity high %','humidity avg %','humidity low %',\\\n",
    "                'Sea Level Pressure high in', 'Sea Level Pressure avg (in)', 'Sea Level Pressure low in',\\\n",
    "                'Visibility high ml', 'Visibility avg ml','Visibility low ml', 'Wind high mph',\\\n",
    "                'Wind avg mph', 'Wind low mph',\\\n",
    "                'Precip sum', 'event', 'wtf', 'ves_a_cagar']\n",
    "print(len(column_names))\n",
    "\n",
    "finalaa = pd.DataFrame(diesaa, columns=column_names)\n",
    "finalaa.shape\n",
    "\n",
    "finalaa.to_csv('weather2015.csv',index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning weather data.\n",
    "#### (Working with csv previously saved from now on)\n",
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain            7\n",
      "Fog             1\n",
      "Thunderstorm    1\n",
      "Name: event, dtype: int64\n",
      "Thunderstorm    1\n",
      "Name: ves_a_cagar, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weather16 = pd.read_csv('weather2016.csv')\n",
    "\n",
    "for i in ['Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']:\n",
    "     weather16 = weather16[weather16.dia != i]\n",
    "weather16.shape\n",
    "\n",
    "\n",
    "\n",
    "def perdelta(start, end, delta):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta\n",
    "\n",
    "escolta = []\n",
    "for mm in perdelta(date(2016, 4, 29), date(2016, 6, 11), timedelta(days=1)):\n",
    "    escolta.append(mm)\n",
    "weather16['date'] = escolta\n",
    "\n",
    "\n",
    "#wtf is just collecting the commas in between event and ves a cagar so I get rid of it\n",
    "weather16.drop('wtf', axis=1, inplace=True)\n",
    "\n",
    "## I want to change rain for thunnderstorm in the cases where ves_a_cagar is thunderstorm\n",
    "print(weather16['event'].value_counts())\n",
    "print(weather16['ves_a_cagar'].value_counts())\n",
    "\n",
    "weather16['event'][weather16['ves_a_cagar'] == 'Thunderstorm'] = 'Thunderstorm' \n",
    "\n",
    "weather16['event'].unique()\n",
    "##I do not need ves-a_cagar anymore\n",
    "weather16.drop('ves_a_cagar', axis=1, inplace=True)\n",
    "\n",
    "weather16['event'] = [c if c in ['Rain', 'Thunderstorm', 'Fog'] else 'Nothing' for c in weather16.event]\n",
    "weather16.to_csv('w2016.csv',index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather15 = pd.read_csv('weather2015.csv')\n",
    "\n",
    "\n",
    "for i in ['Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov']:\n",
    "     weather15 = weather15[weather15.dia != i]\n",
    "weather15.shape\n",
    "\n",
    "\n",
    "\n",
    "def perdelta(start, end, delta):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta\n",
    "\n",
    "escolta = []\n",
    "for mm in perdelta(date(2015, 1, 1), date(2016, 1, 1), timedelta(days=1)):\n",
    "    escolta.append(mm)\n",
    "weather15['date'] = escolta\n",
    "#wtf is just collecting the commas in between event and ves a cagar so I get rid of it\n",
    "weather15.drop('wtf', axis=1, inplace=True)\n",
    "## I want to change rain for thunnderstorm in the cases where ves_a_cagar is thunderstorm\n",
    "weather15['event'][weather15['ves_a_cagar'] == 'Thunderstorm'] = 'Thunderstorm'\n",
    "##Now I can drop 'ves_a_cagar'\n",
    "weather15.drop('ves_a_cagar', axis=1, inplace=True)\n",
    "weather15['event'] = [c if c in ['Rain', 'Thunderstorm', 'Fog'] else 'Nothing' for c in weather15.event]\n",
    "weather15.to_csv('w2015.csv',index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather14 = pd.read_csv('weather2014.csv')\n",
    "\n",
    "\n",
    "for i in ['Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov']:\n",
    "     weather14 = weather14[weather14.dia != i]\n",
    "weather14.shape\n",
    "\n",
    "\n",
    "\n",
    "def perdelta(start, end, delta):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta\n",
    "\n",
    "escolta = []\n",
    "for mm in perdelta(date(2014, 1, 1), date(2015, 1, 1), timedelta(days=1)):\n",
    "    escolta.append(mm)\n",
    "weather14['date'] = escolta\n",
    "#wtf is just collecting the commas in between event and ves a cagar so I get rid of it\n",
    "weather14.drop('wtf', axis=1, inplace=True)\n",
    "## I want to change rain for thunnderstorm in the cases where ves_a_cagar is thunderstorm\n",
    "weather14['event'][weather14['ves_a_cagar'] == 'Thunderstorm'] = 'Thunderstorm'\n",
    "##Now I can drop 'ves_a_cagar'\n",
    "weather14.drop('ves_a_cagar', axis=1, inplace=True)\n",
    "weather14['event'] = [c if c in ['Rain', 'Thunderstorm', 'Fog'] else 'Nothing' for c in weather14.event]\n",
    "weather14.to_csv('w2014.csv',index=False, encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
